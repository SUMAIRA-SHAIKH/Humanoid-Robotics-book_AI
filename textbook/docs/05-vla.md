---
id: vla
title: Module 4 â€” Vision-Language-Action (VLA)
slug: /docs/vla
sidebar_position: 5
---

# Vision-Language-Action (VLA)

Combining LLMs with perception and robot actions.

## Vision-Language Models

- Grounding: Connecting language to visual elements
- Reasoning: Inferring from visual and textual inputs
- Planning: Generating action sequences from instructions

## VLA Systems

- RT-1: Robotics Transformer 1
- RT-2: Robotics Transformer 2 with vision-language models
- Mobile ALOHA: Learning bimanual mobile manipulation

## Challenges

- Embodiment: Translating language to physical actions
- Safety: Ensuring safe robot behavior
- Generalization: Performing unseen tasks